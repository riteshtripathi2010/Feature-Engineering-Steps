{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All Techniques Of Hyper Parameter Optimization\n",
    "#1. GridSearchCV\n",
    "#2. RandomizedSearchCV\n",
    "#3. Bayesian Optimization -Automate Hyperparameter Tuning (Hyperopt)\n",
    "#4. Sequential Model Based Optimization(Tuning a scikit-learn estimator with skopt)\n",
    "#5. Optuna- Automate Hyperparameter Tuning\n",
    "#6. Genetic Algorithms (TPOT Classifier)\n",
    "\n",
    "##Hyperparameter Tunning works well when you have huge amount of data\n",
    "##You can use RandomForestClassifier\n",
    "##You can use RandomForestRegressor\n",
    "#i am using above, because this is going to be my base to understand other MLalgorithms\n",
    "    ##we shouldnt be using all the prefixed parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#some of the warnings from sklearn will be shown, hence using above to ignore them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('https://raw.githubusercontent.com/krishnaik06/All-Hyperparamter-Optimization/master/diabetes.csv')\n",
    "df.head()\n",
    "\n",
    "#prima diabetes from kaggle is the dataset, it has alot of feature and most famous dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6    148.0             72             35     30.5  33.6   \n",
       "1            1     85.0             66             29     30.5  26.6   \n",
       "2            8    183.0             64              0     30.5  23.3   \n",
       "3            1     89.0             66             23     94.0  28.1   \n",
       "4            0    137.0             40             35    168.0  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df['Glucose']=np.where(df['Glucose']==0,df['Glucose'].median(),df['Glucose'])\n",
    "df['Insulin']=np.where(df['Insulin']==0,df['Insulin'].median(),df['Insulin'])\n",
    "df.head()\n",
    "#if we see basically Glucose and Insulin can not have 0 value\n",
    "#therefore wherever we have 0, will be replaced by the median value\n",
    "#and if the value is not 0, we are keeping that same value: ,df['Glucose']\n",
    "\n",
    "#not using mean, bse if there are outliers, it will get affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6    148.0             72             35     30.5  33.6   \n",
      "1            1     85.0             66             29     30.5  26.6   \n",
      "2            8    183.0             64              0     30.5  23.3   \n",
      "3            1     89.0             66             23     94.0  28.1   \n",
      "4            0    137.0             40             35    168.0  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  \n",
      "0                     0.627   50  \n",
      "1                     0.351   31  \n",
      "2                     0.672   32  \n",
      "3                     0.167   21  \n",
      "4                     2.288   33  \n",
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: Outcome, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since i am using RandomForest, do i need Scaling?\n",
    "#Ans: NO, RF works on DT, in DT you create branches\n",
    "\n",
    "#### Independent And Dependent features\n",
    "#shorter way of dividing data\n",
    "X=df.drop('Outcome',axis=1)\n",
    "y=df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6    148.0             72             35     30.5  33.6   \n",
       "1              1     85.0             66             29     30.5  26.6   \n",
       "2              8    183.0             64              0     30.5  23.3   \n",
       "3              1     89.0             66             23     94.0  28.1   \n",
       "4              0    137.0             40             35    168.0  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10    101.0             76             48    180.0  32.9   \n",
       "764            2    122.0             70             27     30.5  36.8   \n",
       "765            5    121.0             72             23    112.0  26.2   \n",
       "766            1    126.0             60              0     30.5  30.1   \n",
       "767            1     93.0             70             31     30.5  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "0                       0.627   50  \n",
       "1                       0.351   31  \n",
       "2                       0.672   32  \n",
       "3                       0.167   21  \n",
       "4                       2.288   33  \n",
       "..                        ...  ...  \n",
       "763                     0.171   63  \n",
       "764                     0.340   27  \n",
       "765                     0.245   30  \n",
       "766                     0.349   47  \n",
       "767                     0.315   23  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X,columns=df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=0)\n",
    "#20% as my test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier=RandomForestClassifier(n_estimators=10).fit(X_train,y_train)\n",
    "prediction=rf_classifier.predict(X_test)\n",
    "\n",
    "#by default, estimators are 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()\n",
    "#this is an imbalanced data set, but will go through it as we are looking after hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92 15]\n",
      " [16 31]]\n",
      "0.7987012987012987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86       107\n",
      "           1       0.67      0.66      0.67        47\n",
      "\n",
      "    accuracy                           0.80       154\n",
      "   macro avg       0.76      0.76      0.76       154\n",
      "weighted avg       0.80      0.80      0.80       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "print(confusion_matrix(y_test,prediction))#confusion with y_test and prediction\n",
    "print(accuracy_score(y_test,prediction))\n",
    "print(classification_report(y_test,prediction))\n",
    "#i am egtting 79% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###The main parameters used by a Random Forest Classifier are:\n",
    "\n",
    "#1. criterion = the function used to evaluate the quality of a split.\n",
    "#2. max_depth = maximum number of levels allowed in each tree.\n",
    "#3. max_features = maximum number of features considered when splitting a node.\n",
    "#4. min_samples_leaf = minimum number of samples which can be stored in a tree leaf.\n",
    "#5. min_samples_split = minimum number of samples necessary in a node to cause node splitting.\n",
    "#6. n_estimators = number of trees in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98  9]\n",
      " [18 29]]\n",
      "0.8246753246753247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       107\n",
      "           1       0.76      0.62      0.68        47\n",
      "\n",
      "    accuracy                           0.82       154\n",
      "   macro avg       0.80      0.77      0.78       154\n",
      "weighted avg       0.82      0.82      0.82       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Manual Hyperparameter Tuning\n",
    "#based on my mood, i am selecting just like that\n",
    "model=RandomForestClassifier(n_estimators=300,criterion='entropy',\n",
    "                             max_features='sqrt',min_samples_leaf=10,random_state=100).fit(X_train,y_train)\n",
    "predictions=model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(accuracy_score(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "#82%\n",
    "#values to be changed have to be based on some techniques not based on your mood\n",
    "#that technique is called hyperparamter optimization\n",
    "    #GridsearchCV and Randomized Search CV\n",
    "\n",
    "#whenever hyperparamter optimization has to take place, always start with Randomised, bse it narrows down results\n",
    "#then apply Grid Search\n",
    "\n",
    "#Eg: four location, A,B,C,D --> and you have to find Ritesh\n",
    "#Randomised will do some random seelction with 82%or mroe and give results as B & C\n",
    "#GridSearch will look into B and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "#from below, these are the values that will be selected by Randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [1, 3, 4, 5, 7, 9], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['entropy', 'gini']}\n"
     ]
    }
   ],
   "source": [
    "###2. Randomized Search Cv    -- First Selection\n",
    "#fir Randomized, i have to give parameters, estimators, max feat, max dept, min samples, min sample leaf,\n",
    "#estimators are number of trees in random forest\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "#by default, estimaors are 100, here we are choosing between 200 to 2000 with 10 different numbers\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "#first you try with auto then sqrt and then log2\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [1,3,4,5,7,9]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['entropy','gini']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
       "                                        'max_depth': [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [1, 3, 4, 5, 7, 9],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=100, verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basically u have to initialize a randomforestclassifier with all the default values\n",
    "rf=RandomForestClassifier()\n",
    "rf_randomcv=RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, cv=3, verbose=2,\n",
    "                               random_state=100, n_jobs=-1)\n",
    "#CV=3, \n",
    "#cv a technique, the number of cv u say, is the number of train split will be splitted sequentialy\n",
    "#njobs = to use 1 core of my machine\n",
    "    #in 24.3s it has done 33 tasks\n",
    "    \n",
    "\n",
    "#here 3 fits will be happening, 100 * 3\n",
    "\n",
    "\n",
    "### fit the randomized model\n",
    "rf_randomcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1600,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 560,\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomcv.best_params_\n",
    "#after execution of all 300 fits, we see which is the best parameters\n",
    "#in Randomized, i have found out that these are the regions where my model will perform the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
       "                                        'max_depth': [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [1, 3, 4, 5, 7, 9],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=100, verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomcv\n",
    "#just checking how its done, not an important step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=560, min_samples_split=4, n_estimators=1600)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomcv.best_estimator_\n",
    "#here i have taken , max dept 560 and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_grid=rf_randomcv.best_estimator_\n",
    "#imp step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94 13]\n",
      " [15 32]]\n",
      "Accuracy Score 0.8181818181818182\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       107\n",
      "           1       0.71      0.68      0.70        47\n",
      "\n",
      "    accuracy                           0.82       154\n",
      "   macro avg       0.79      0.78      0.78       154\n",
      "weighted avg       0.82      0.82      0.82       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=best_random_grid.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred)))\n",
    "\n",
    "#now my accuracy score is 81%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1600,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 560,\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###3. GridSearch CV\n",
    "rf_randomcv.best_params_\n",
    "#i am applying all those parameters which we found out from randomized, will be given as input \n",
    "#as shown in line 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 3, 5],)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[rf_randomcv.best_params_['min_samples_leaf'],#here i am taking 4leafs \n",
    "                         rf_randomcv.best_params_['min_samples_leaf']+2, #here i am taking 4+2=6 \n",
    "                         rf_randomcv.best_params_['min_samples_leaf'] + 4],#taking 4+4=8 leafs\n",
    "#as shown below, \n",
    "#1,3,5 are min sample leafs are getting selected\n",
    "\n",
    "#same for min splits should be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': ['gini'], 'max_depth': [560], 'max_features': ['auto'], 'min_samples_leaf': [1, 3, 5], 'min_samples_split': [2, 3, 4, 5, 6], 'n_estimators': [1400, 1500, 1600, 1700, 1800]}\n"
     ]
    }
   ],
   "source": [
    "#Now we build GridSearchCV, \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': [rf_randomcv.best_params_['criterion']],\n",
    "    'max_depth': [rf_randomcv.best_params_['max_depth']],\n",
    "    'max_features': [rf_randomcv.best_params_['max_features']],\n",
    "    'min_samples_leaf': [rf_randomcv.best_params_['min_samples_leaf'],#here i am taking 1leafs \n",
    "                         rf_randomcv.best_params_['min_samples_leaf']+2, #here i am taking 1+2=3 \n",
    "                         rf_randomcv.best_params_['min_samples_leaf'] + 4],#taking 1+5=8 leafs\n",
    "    'min_samples_split': [rf_randomcv.best_params_['min_samples_split'] - 2,\n",
    "                          rf_randomcv.best_params_['min_samples_split'] - 1,\n",
    "                          rf_randomcv.best_params_['min_samples_split'], \n",
    "                          rf_randomcv.best_params_['min_samples_split'] +1,\n",
    "                          rf_randomcv.best_params_['min_samples_split'] + 2],\n",
    "    'n_estimators': [rf_randomcv.best_params_['n_estimators'] - 200, rf_randomcv.best_params_['n_estimators'] - 100, \n",
    "                     rf_randomcv.best_params_['n_estimators'], \n",
    "                     rf_randomcv.best_params_['n_estimators'] + 100, rf_randomcv.best_params_['n_estimators'] + 200]\n",
    "}\n",
    "\n",
    "print(param_grid)\n",
    "#here u dont have an option of iteration like the way we have in RandomSearchCV\n",
    "#total number of iterations will be\n",
    "#crit - 1\n",
    "#maxdept - 1\n",
    "#maxfeat - 1\n",
    "#maxsamplleaf - 3\n",
    "#split - 5\n",
    "#estima - 5\n",
    "#total = 1*1*1*3*5*5= 75 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 75 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed: 15.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': [560],\n",
       "                         'max_features': ['auto'],\n",
       "                         'min_samples_leaf': [1, 3, 5],\n",
       "                         'min_samples_split': [2, 3, 4, 5, 6],\n",
       "                         'n_estimators': [1400, 1500, 1600, 1700, 1800]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Fit the grid_search to the data\n",
    "rf=RandomForestClassifier()\n",
    "grid_search=GridSearchCV(estimator=rf,param_grid=param_grid,cv=10,n_jobs=-1,verbose=2)\n",
    "#first parameter - estimator\n",
    "#paramgrid = as of above the values we just executed\n",
    "#verbose is used to display all those in pink color as shown below\n",
    "\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=560, min_samples_leaf=5, min_samples_split=6,\n",
       "                       n_estimators=1800)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after executing above, we find the best estimators for GridSearch\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving above in a new variable\n",
    "best_grid=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=560, min_samples_leaf=5, min_samples_split=6,\n",
       "                       n_estimators=1800)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seeing the values of the variables\n",
    "best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97 10]\n",
      " [18 29]]\n",
      "Accuracy Score 0.8181818181818182\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       107\n",
      "           1       0.74      0.62      0.67        47\n",
      "\n",
      "    accuracy                           0.82       154\n",
      "   macro avg       0.79      0.76      0.77       154\n",
      "weighted avg       0.81      0.82      0.81       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#FINAL STEP, accuracy is: \n",
    "y_pred=best_grid.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred)))\n",
    "#in MAchine Learning u can not use GPU, \n",
    "#In XGBOOST u can use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######NEXT TECHNIQUE, start from 24.27\n",
    "\n",
    "####4. Automated Hyperparameter Tuning (Bayesian Optimization) using Hyperpot\n",
    "#Automated Hyperparameter Tuning can be done by using techniques such as\n",
    "\n",
    "#1. Bayesian Optimization\n",
    "#2. Gradient Descent\n",
    "#3. Evolutionary Algorithms\n",
    "\n",
    "#Conda forge hyperpot\n",
    "#!pip install\n",
    "#pip install hyperpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian Optimization using Hyperpot\n",
    "#Bayesian optimization uses probability to find the minimum of a function.\n",
    "#The final aim is to find the input value to a function which can gives us the lowest possible output value\n",
    "#It usually performs better than random,grid and manual search providing better performance in the testing phase and reduced optimization time.\n",
    "#In Hyperopt, Bayesian Optimization can be implemented giving 3 three main parameters to the function fmin.\n",
    "##Inshort, its better than Random and Grid due to reduced optimization time\n",
    "\n",
    "#The three parameters are:\n",
    "#1. Objective Function = defines the loss function to minimize.\n",
    "#2. Domain Space = defines the range of input values to test (in Bayesian Optimization this space creates a probability distribution for each of the used Hyperparameters).\n",
    "#3. Optimization Algorithm = defines the search algorithm to use to select the best input values to use in each new iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "\n",
    "#hp: whether i am defining an integer, floating values or some choice functions\n",
    "#hp.choice: to select two paramters as entropy, gini\n",
    "#hp.quniform: to select integer values with range\n",
    "#hp.uniform:check from the code\n",
    "\n",
    "#Trials used in minimizing the function\n",
    "\n",
    "#TPE: used as algo, algorithm\n",
    "\n",
    "#look below by what all different ho.choice and hp.uniform are representing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Step, this step is similar to what we have been using in Random and Grid in Line 25 and 13\n",
    "#First i have to define space\n",
    "#OR DOMAIN SPACE\n",
    "\n",
    "#Space is defined as all my parameters that will be defined inside my RandomForest\n",
    "#with hyperopt, we can define all these below\n",
    "space = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
    "        'max_depth': hp.quniform('max_depth', 10, 1200, 10),#taking 10 num btn 10 and 1200\n",
    "        'max_features': hp.choice('max_features', ['auto', 'sqrt','log2', None]),\n",
    "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
    "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
    "        'n_estimators' : hp.choice('n_estimators', [10, 50, 300, 750, 1200,1300,1500])\n",
    "         #i can write above as\n",
    "         #'n_estimators' : hp.quniform('n_estimators', [10, 1500, 10])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': <hyperopt.pyll.base.Apply at 0x7fca32702410>,\n",
       " 'max_depth': <hyperopt.pyll.base.Apply at 0x7fca32702d50>,\n",
       " 'max_features': <hyperopt.pyll.base.Apply at 0x7fca327020d0>,\n",
       " 'min_samples_leaf': <hyperopt.pyll.base.Apply at 0x7fca326e52d0>,\n",
       " 'min_samples_split': <hyperopt.pyll.base.Apply at 0x7fca326e5450>,\n",
       " 'n_estimators': <hyperopt.pyll.base.Apply at 0x7fca326e55d0>}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space\n",
    "#my space values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW WE DEFINE OBJECTIVE FUNCTION\n",
    "\n",
    "def objective(space):\n",
    "    model = RandomForestClassifier(criterion = space['criterion'], max_depth = space['max_depth'],\n",
    "                                 max_features = space['max_features'],\n",
    "                                 min_samples_leaf = space['min_samples_leaf'],\n",
    "                                 min_samples_split = space['min_samples_split'],\n",
    "                                 n_estimators = space['n_estimators'], \n",
    "                                 )\n",
    "    \n",
    "    accuracy = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "    #why mean: after every iteration i will be getting some value\n",
    "    #there after 5 iterations 5 values\n",
    "    #mean of 5 iterations\n",
    "\n",
    "    # We aim to maximize accuracy, therefore we return it as a negative value\n",
    "    #i am basically printing above accuracy in here\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [08:08<00:00,  6.11s/trial, best loss: -0.767093162734906] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 1,\n",
       " 'max_depth': 750.0,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 0.123522614987325,\n",
       " 'min_samples_split': 0.11119939596339183,\n",
       " 'n_estimators': 3}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TRIALS\n",
    "from sklearn.model_selection import cross_val_score\n",
    "trials = Trials()#created an object\n",
    "best = fmin(fn= objective,\n",
    "            space= space,\n",
    "            algo= tpe.suggest,\n",
    "            max_evals = 80,\n",
    "            trials= trials)\n",
    "best\n",
    "#below are my best values but they are in key value pairs but i have to do the mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini\n",
      "log2\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "#MAPPING:\n",
    "#Entropy: i have taken as 0 and so on\n",
    "crit = {0: 'entropy', 1: 'gini'}\n",
    "feat = {0: 'auto', 1: 'sqrt', 2: 'log2', 3: None}\n",
    "est = {0: 10, 1: 50, 2: 300, 3: 750, 4: 1200,5:1300,6:1500}\n",
    "\n",
    "\n",
    "print(crit[best['criterion']])\n",
    "print(feat[best['max_features']])\n",
    "print(est[best['n_estimators']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.123522614987325"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best['min_samples_leaf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97 10]\n",
      " [25 22]]\n",
      "0.7727272727272727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       107\n",
      "           1       0.69      0.47      0.56        47\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.74      0.69      0.70       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainedforest = RandomForestClassifier(criterion = crit[best['criterion']], max_depth = best['max_depth'], \n",
    "                                       max_features = feat[best['max_features']], \n",
    "                                       min_samples_leaf = best['min_samples_leaf'], \n",
    "                                       min_samples_split = best['min_samples_split'], \n",
    "                                       n_estimators = est[best['n_estimators']]).fit(X_train,y_train)\n",
    "predictionforest = trainedforest.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictionforest))\n",
    "print(accuracy_score(y_test,predictionforest))\n",
    "print(classification_report(y_test,predictionforest))\n",
    "acc5 = accuracy_score(y_test,predictionforest)\n",
    "\n",
    "#getting 77% as accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FINAL ALGORITHM\n",
    "####5. Genetic Algorithms\n",
    "#Fairly New Concept\n",
    "#Genetic Algorithms tries to apply NAtural SElection mechanisms to Machine Learning contexts.\n",
    "\n",
    "#Let's immagine we create a population of N Machine Learning models with some predifined Hyperparameters.\n",
    "    #we use 20models, and see each performance and we select top 10 models with best accuracy\n",
    "#We can then calculate the accuracy of each model and decide to keep just half of the models \n",
    "    #(the ones that performs best). \n",
    "    #suppose my 10 models have been created, similar to those 10 models we can create more offsprings with ..\n",
    "        #similar parameters\n",
    "    #N can be defined by us\n",
    "    \n",
    "#We can now generate some offsprings having similar Hyperparameters to the ones of the best models \n",
    "    #so that go get again a population of N models. \n",
    "#At this point we can again caltulate the accuracy of each model and repeate the cycle for a defined number of generations. In this way, just the best models will survive at the end of the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 5, 10, 14], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['entropy', 'gini']}\n"
     ]
    }
   ],
   "source": [
    "##First we will define PARAMETERS \n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,14]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8]\n",
    "\n",
    "# Create the random grid\n",
    "param = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['entropy','gini']}\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=84.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.7589975384093031\n",
      "Generation 2 - Current best internal CV score: 0.7638252270605211\n",
      "Generation 3 - Current best internal CV score: 0.7638252270605211\n",
      "Generation 4 - Current best internal CV score: 0.7638252270605211\n",
      "Generation 5 - Current best internal CV score: 0.7638252270605211\n",
      "Best pipeline: RandomForestClassifier(RandomForestClassifier(input_matrix, criterion=gini, max_depth=1000, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=1000), criterion=entropy, max_depth=340, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, n_estimators=800)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.ensemble.RandomForestClassifier': {'criterion': ['entropy',\n",
       "                                                                                      'gini'],\n",
       "                                                                        'max_depth': [10,\n",
       "                                                                                      120,\n",
       "                                                                                      230,\n",
       "                                                                                      340,\n",
       "                                                                                      450,\n",
       "                                                                                      560,\n",
       "                                                                                      670,\n",
       "                                                                                      780,\n",
       "                                                                                      890,\n",
       "                                                                                      1000],\n",
       "                                                                        'max_features': ['auto',\n",
       "                                                                                         'sqrt',\n",
       "                                                                                         'log2'],\n",
       "                                                                        'min_samples_leaf': [1,\n",
       "                                                                                             2,\n",
       "                                                                                             4,\n",
       "                                                                                             6,\n",
       "                                                                                             8],\n",
       "                                                                        'min_samples_split': [2,\n",
       "                                                                                              5,\n",
       "                                                                                              10,\n",
       "                                                                                              14],\n",
       "                                                                        'n_estimators': [200,\n",
       "                                                                                         400,\n",
       "                                                                                         600,\n",
       "                                                                                         800,\n",
       "                                                                                         1000,\n",
       "                                                                                         1200,\n",
       "                                                                                         1400,\n",
       "                                                                                         1600,\n",
       "                                                                                         1800,\n",
       "                                                                                         2000]}},\n",
       "               cv=4, early_stop=12, generations=5,\n",
       "               log_file=<ipykernel.iostream.OutStream object at 0x7ff44c55ea50>,\n",
       "               offspring_size=12, population_size=24, scoring='accuracy',\n",
       "               verbosity=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "#this will install tensorflow and keras as well\n",
    "\n",
    "#generations is imp\n",
    "#offspring is 50% of this\n",
    "#make sure u write the whole path for config_dist: this means which alog i will be using\n",
    "#param is what we have defined above\n",
    "tpot_classifier = TPOTClassifier(generations= 5, population_size= 24, offspring_size= 12,\n",
    "                                 verbosity= 2, early_stop= 12,\n",
    "                                 config_dict={'sklearn.ensemble.RandomForestClassifier': param}, \n",
    "                                 cv = 4, scoring = 'accuracy')\n",
    "tpot_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8246753246753247\n"
     ]
    }
   ],
   "source": [
    "accuracy = tpot_classifier.score(X_test, y_test)#first it will find the predcitions, \n",
    "#then it wil compare that prediction with this y_test\n",
    "print(accuracy)\n",
    "\n",
    "#Adv: works well\n",
    "#its creating offsprings on models that are working well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##       Next Technique\n",
    "\n",
    "####6. Optimize hyperparameters of the model using OPTUNA\n",
    "#The hyperparameters of the above algorithm are n_estimators and max_depth for which we can try different \n",
    "    #values to see if the model accuracy can be improved.\n",
    "#The objective function is modified to accept a trial object.\n",
    "#This trial has several methods for sampling hyperparameters. \n",
    "#We create a study to run the hyperparameter optimization and finally read the best hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import sklearn.svm\n",
    "def objective(trial):\n",
    "    \n",
    "    #i am doing comparison btn Rf and SVC\n",
    "\n",
    "    classifier = trial.suggest_categorical('classifier', ['RandomForest', 'SVC'])\n",
    "    \n",
    "    if classifier == 'RandomForest':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 200, 2000,10)\n",
    "        max_depth = int(trial.suggest_float('max_depth', 10, 100, log=True))\n",
    "\n",
    "        clf = sklearn.ensemble.RandomForestClassifier(\n",
    "            n_estimators=n_estimators, max_depth=max_depth)\n",
    "    else:\n",
    "        c = trial.suggest_float('svc_c', 1e-10, 1e10, log=True)\n",
    "        \n",
    "        clf = sklearn.svm.SVC(C=c, gamma='auto')\n",
    "\n",
    "    return sklearn.model_selection.cross_val_score(\n",
    "        clf,X_train,y_train, n_jobs=-1, cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-07-28 15:18:40,361] Finished trial#0 with value: 0.7524310537223019 with parameters: {'classifier': 'RandomForest', 'n_estimators': 980, 'max_depth': 35.153457917697615}. Best is trial#0 with value: 0.7524310537223019.\n",
      "[I 2020-07-28 15:18:44,199] Finished trial#1 with value: 0.7507890961262554 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1650, 'max_depth': 51.29493852660953}. Best is trial#0 with value: 0.7524310537223019.\n",
      "[I 2020-07-28 15:18:44,277] Finished trial#2 with value: 0.640068547744301 with parameters: {'classifier': 'SVC', 'svc_c': 1.904629442225009e-08}. Best is trial#0 with value: 0.7524310537223019.\n",
      "[I 2020-07-28 15:18:44,365] Finished trial#3 with value: 0.640068547744301 with parameters: {'classifier': 'SVC', 'svc_c': 217532305.94679388}. Best is trial#0 with value: 0.7524310537223019.\n",
      "[I 2020-07-28 15:18:44,446] Finished trial#4 with value: 0.640068547744301 with parameters: {'classifier': 'SVC', 'svc_c': 1.316093867024423e-10}. Best is trial#0 with value: 0.7524310537223019.\n",
      "[I 2020-07-28 15:18:44,530] Finished trial#5 with value: 0.640068547744301 with parameters: {'classifier': 'SVC', 'svc_c': 0.050766328629379305}. Best is trial#0 with value: 0.7524310537223019.\n",
      "[I 2020-07-28 15:18:48,255] Finished trial#6 with value: 0.7508050374621393 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1770, 'max_depth': 14.380414352324145}. Best is trial#0 with value: 0.7524310537223019.\n",
      "[I 2020-07-28 15:18:50,798] Finished trial#7 with value: 0.7508209787980232 with parameters: {'classifier': 'RandomForest', 'n_estimators': 900, 'max_depth': 75.10333454393223}. Best is trial#0 with value: 0.7524310537223019.\n",
      "[I 2020-07-28 15:18:56,071] Finished trial#8 with value: 0.7491790212019768 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1820, 'max_depth': 21.0523167987757}. Best is trial#0 with value: 0.7524310537223019.\n",
      "[I 2020-07-28 15:18:56,161] Finished trial#9 with value: 0.640068547744301 with parameters: {'classifier': 'SVC', 'svc_c': 2.8052304800877903e-08}. Best is trial#0 with value: 0.7524310537223019.\n",
      "[I 2020-07-28 15:18:57,121] Finished trial#10 with value: 0.7508050374621393 with parameters: {'classifier': 'RandomForest', 'n_estimators': 370, 'max_depth': 34.08668617300936}. Best is trial#0 with value: 0.7524310537223019.\n",
      "[I 2020-07-28 15:19:00,418] Finished trial#11 with value: 0.7410329985652798 with parameters: {'classifier': 'RandomForest', 'n_estimators': 840, 'max_depth': 95.98850286050488}. Best is trial#0 with value: 0.7524310537223019.\n",
      "[I 2020-07-28 15:19:03,953] Finished trial#12 with value: 0.7507970667941973 with parameters: {'classifier': 'RandomForest', 'n_estimators': 940, 'max_depth': 89.46827607684288}. Best is trial#0 with value: 0.7524310537223019.\n",
      "[I 2020-07-28 15:19:08,016] Finished trial#13 with value: 0.7556910569105691 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1200, 'max_depth': 53.1911450614467}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:19:12,800] Finished trial#14 with value: 0.7459110473457676 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1320, 'max_depth': 36.56933022365541}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:19:15,557] Finished trial#15 with value: 0.7508050374621393 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1230, 'max_depth': 52.11997101958165}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:19:16,691] Finished trial#16 with value: 0.7475370636059302 with parameters: {'classifier': 'RandomForest', 'n_estimators': 490, 'max_depth': 22.75121683079246}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:19:19,894] Finished trial#17 with value: 0.7459110473457676 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1350, 'max_depth': 53.09495472276604}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:19:21,337] Finished trial#18 with value: 0.7475530049418141 with parameters: {'classifier': 'RandomForest', 'n_estimators': 660, 'max_depth': 24.77116955600645}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:19:24,570] Finished trial#19 with value: 0.7540650406504065 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1490, 'max_depth': 42.453368089958}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:19:28,427] Finished trial#20 with value: 0.7540650406504065 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1540, 'max_depth': 67.42127937525527}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:19:34,113] Finished trial#21 with value: 0.7540570699824646 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1540, 'max_depth': 67.65261883910084}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:19:38,515] Finished trial#22 with value: 0.75242308305436 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1480, 'max_depth': 45.280941498621715}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:19:44,726] Finished trial#23 with value: 0.7508050374621393 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1980, 'max_depth': 70.35743111888638}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:19:48,755] Finished trial#24 with value: 0.7508050374621393 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1130, 'max_depth': 62.8037183275958}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:19:54,384] Finished trial#25 with value: 0.7459269886816515 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1440, 'max_depth': 42.139931948186984}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:19:58,865] Finished trial#26 with value: 0.7508050374621393 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1660, 'max_depth': 82.94164698265914}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:20:03,587] Finished trial#27 with value: 0.75242308305436 with parameters: {'classifier': 'RandomForest', 'n_estimators': 2000, 'max_depth': 27.787837203230506}. Best is trial#13 with value: 0.7556910569105691.\n",
      "[I 2020-07-28 15:20:06,415] Finished trial#28 with value: 0.7573170731707317 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1240, 'max_depth': 58.92034240897328}. Best is trial#28 with value: 0.7573170731707317.\n",
      "[I 2020-07-28 15:20:09,075] Finished trial#29 with value: 0.7556830862426271 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1190, 'max_depth': 61.584947064241476}. Best is trial#28 with value: 0.7573170731707317.\n",
      "[I 2020-07-28 15:20:11,629] Finished trial#30 with value: 0.7475609756097561 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1120, 'max_depth': 57.14633027737474}. Best is trial#28 with value: 0.7573170731707317.\n",
      "[I 2020-07-28 15:20:14,507] Finished trial#31 with value: 0.7524390243902439 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1260, 'max_depth': 64.58649835401236}. Best is trial#28 with value: 0.7573170731707317.\n",
      "[I 2020-07-28 15:20:17,353] Finished trial#32 with value: 0.7540650406504065 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1090, 'max_depth': 97.45457742106265}. Best is trial#28 with value: 0.7573170731707317.\n",
      "[I 2020-07-28 15:20:19,901] Finished trial#33 with value: 0.760569105691057 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1060, 'max_depth': 92.17985059870648}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:22,218] Finished trial#34 with value: 0.7491551091981509 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1020, 'max_depth': 81.35064891334487}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:22,313] Finished trial#35 with value: 0.640068547744301 with parameters: {'classifier': 'SVC', 'svc_c': 131680726.60756314}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:24,033] Finished trial#36 with value: 0.7459110473457676 with parameters: {'classifier': 'RandomForest', 'n_estimators': 750, 'max_depth': 46.98553844620239}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:24,120] Finished trial#37 with value: 0.640068547744301 with parameters: {'classifier': 'SVC', 'svc_c': 12.015345592356347}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:27,177] Finished trial#38 with value: 0.7507970667941973 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1190, 'max_depth': 60.23810976408362}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:30,741] Finished trial#39 with value: 0.7540650406504065 with parameters: {'classifier': 'RandomForest', 'n_estimators': 980, 'max_depth': 40.040779422465924}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:30,905] Finished trial#40 with value: 0.640068547744301 with parameters: {'classifier': 'SVC', 'svc_c': 45.96885384839014}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:34,441] Finished trial#41 with value: 0.7507890961262554 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1320, 'max_depth': 76.88593195272976}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:38,043] Finished trial#42 with value: 0.7508130081300813 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1400, 'max_depth': 56.93298606702935}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:40,317] Finished trial#43 with value: 0.7508050374621393 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1040, 'max_depth': 37.19588426336277}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:42,320] Finished trial#44 with value: 0.7508130081300813 with parameters: {'classifier': 'RandomForest', 'n_estimators': 840, 'max_depth': 10.031090175902659}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:44,639] Finished trial#45 with value: 0.7508130081300813 with parameters: {'classifier': 'RandomForest', 'n_estimators': 950, 'max_depth': 49.046274781708355}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:47,523] Finished trial#46 with value: 0.7459190180137095 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1190, 'max_depth': 31.74550074746494}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:51,063] Finished trial#47 with value: 0.7556830862426271 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1610, 'max_depth': 87.83020359094087}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:54,971] Finished trial#48 with value: 0.7491869918699187 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1790, 'max_depth': 98.62286626696297}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:58,542] Finished trial#49 with value: 0.7524310537223019 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1600, 'max_depth': 86.2728617185028}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:20:58,625] Finished trial#50 with value: 0.640068547744301 with parameters: {'classifier': 'SVC', 'svc_c': 0.0006043737031960153}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:00,591] Finished trial#51 with value: 0.7556830862426271 with parameters: {'classifier': 'RandomForest', 'n_estimators': 860, 'max_depth': 39.332565267050754}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:02,330] Finished trial#52 with value: 0.755699027578511 with parameters: {'classifier': 'RandomForest', 'n_estimators': 660, 'max_depth': 75.44255965689854}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:03,850] Finished trial#53 with value: 0.7459110473457676 with parameters: {'classifier': 'RandomForest', 'n_estimators': 660, 'max_depth': 75.107395556915}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:05,012] Finished trial#54 with value: 0.7475450342738722 with parameters: {'classifier': 'RandomForest', 'n_estimators': 500, 'max_depth': 89.39367115695035}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:06,913] Finished trial#55 with value: 0.7540570699824646 with parameters: {'classifier': 'RandomForest', 'n_estimators': 800, 'max_depth': 53.25206224549881}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:08,592] Finished trial#56 with value: 0.7475450342738722 with parameters: {'classifier': 'RandomForest', 'n_estimators': 640, 'max_depth': 75.21812145308438}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:11,007] Finished trial#57 with value: 0.744293001753547 with parameters: {'classifier': 'RandomForest', 'n_estimators': 890, 'max_depth': 97.17765402044706}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:12,342] Finished trial#58 with value: 0.7426590148254424 with parameters: {'classifier': 'RandomForest', 'n_estimators': 540, 'max_depth': 34.39955897102608}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:13,327] Finished trial#59 with value: 0.7508050374621393 with parameters: {'classifier': 'RandomForest', 'n_estimators': 300, 'max_depth': 56.053834936693725}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:16,332] Finished trial#60 with value: 0.7524469950581859 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1230, 'max_depth': 69.10690602080636}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:23,594] Finished trial#61 with value: 0.7491790212019768 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1880, 'max_depth': 63.2263992058205}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:26,889] Finished trial#62 with value: 0.7459190180137095 with parameters: {'classifier': 'RandomForest', 'n_estimators': 760, 'max_depth': 49.5787969416128}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:29,789] Finished trial#63 with value: 0.7426669854933844 with parameters: {'classifier': 'RandomForest', 'n_estimators': 890, 'max_depth': 70.73299159061808}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:32,729] Finished trial#64 with value: 0.7540570699824646 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1070, 'max_depth': 80.73210016849303}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:36,488] Finished trial#65 with value: 0.7491790212019768 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1350, 'max_depth': 90.83799063572111}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:39,862] Finished trial#66 with value: 0.7508130081300813 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1180, 'max_depth': 42.95317139280438}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:41,599] Finished trial#67 with value: 0.7459190180137095 with parameters: {'classifier': 'RandomForest', 'n_estimators': 600, 'max_depth': 38.7050822060712}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:46,723] Finished trial#68 with value: 0.7475530049418141 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1710, 'max_depth': 60.349633650003085}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:49,963] Finished trial#69 with value: 0.7508130081300813 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1260, 'max_depth': 71.8753088443016}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:52,514] Finished trial#70 with value: 0.7589510600988363 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1140, 'max_depth': 52.804959951577324}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:55,025] Finished trial#71 with value: 0.7524310537223019 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1140, 'max_depth': 53.23620193727333}. Best is trial#33 with value: 0.760569105691057.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-07-28 15:21:57,378] Finished trial#72 with value: 0.7491710505340348 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1060, 'max_depth': 45.36055571095844}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:21:59,650] Finished trial#73 with value: 0.7475450342738722 with parameters: {'classifier': 'RandomForest', 'n_estimators': 990, 'max_depth': 65.37338750428702}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:02,907] Finished trial#74 with value: 0.7556830862426271 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1300, 'max_depth': 57.4729100894614}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:09,073] Finished trial#75 with value: 0.7524310537223019 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1360, 'max_depth': 17.97776639427425}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:12,796] Finished trial#76 with value: 0.7459110473457676 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1130, 'max_depth': 81.5043529343441}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:16,275] Finished trial#77 with value: 0.7524390243902439 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1270, 'max_depth': 59.695778131387804}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:16,407] Finished trial#78 with value: 0.640068547744301 with parameters: {'classifier': 'SVC', 'svc_c': 65916.92466970223}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:20,814] Finished trial#79 with value: 0.7540490993145226 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1290, 'max_depth': 48.513804383175135}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:22,939] Finished trial#80 with value: 0.7459269886816515 with parameters: {'classifier': 'RandomForest', 'n_estimators': 700, 'max_depth': 55.51716689373635}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:26,962] Finished trial#81 with value: 0.7524310537223019 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1450, 'max_depth': 51.68814450215091}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:30,632] Finished trial#82 with value: 0.7508050374621393 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1390, 'max_depth': 28.36000837432705}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:33,946] Finished trial#83 with value: 0.7540650406504065 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1190, 'max_depth': 61.11589903117548}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:36,452] Finished trial#84 with value: 0.7524310537223019 with parameters: {'classifier': 'RandomForest', 'n_estimators': 930, 'max_depth': 44.97697151559963}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:39,229] Finished trial#85 with value: 0.744285031085605 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1010, 'max_depth': 67.94850566234798}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:42,921] Finished trial#86 with value: 0.7459269886816515 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1520, 'max_depth': 77.59850493805313}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:45,797] Finished trial#87 with value: 0.7491790212019768 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1110, 'max_depth': 92.48342496803546}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:47,882] Finished trial#88 with value: 0.7508050374621393 with parameters: {'classifier': 'RandomForest', 'n_estimators': 840, 'max_depth': 84.78921264707175}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:50,577] Finished trial#89 with value: 0.7459349593495935 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1220, 'max_depth': 40.85979573020467}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:53,151] Finished trial#90 with value: 0.7393990116371753 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1160, 'max_depth': 65.43207301837977}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:55,529] Finished trial#91 with value: 0.7540650406504065 with parameters: {'classifier': 'RandomForest', 'n_estimators': 970, 'max_depth': 30.408638093765866}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:22:57,978] Finished trial#92 with value: 0.744293001753547 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1090, 'max_depth': 92.97950524899075}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:23:01,727] Finished trial#93 with value: 0.7508050374621393 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1670, 'max_depth': 57.81402565762136}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:23:05,277] Finished trial#94 with value: 0.7540570699824646 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1600, 'max_depth': 37.329291671123364}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:23:08,216] Finished trial#95 with value: 0.7508130081300813 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1310, 'max_depth': 71.61992746123322}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:23:09,382] Finished trial#96 with value: 0.744300972421489 with parameters: {'classifier': 'RandomForest', 'n_estimators': 420, 'max_depth': 61.81345977933313}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:23:09,463] Finished trial#97 with value: 0.640068547744301 with parameters: {'classifier': 'SVC', 'svc_c': 0.0002201969687049116}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:23:12,154] Finished trial#98 with value: 0.7556830862426271 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1220, 'max_depth': 54.137054334544025}. Best is trial#33 with value: 0.760569105691057.\n",
      "[I 2020-07-28 15:23:14,873] Finished trial#99 with value: 0.7589590307667783 with parameters: {'classifier': 'RandomForest', 'n_estimators': 1230, 'max_depth': 54.62721088659163}. Best is trial#33 with value: 0.760569105691057.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.760569105691057\n",
      "Best hyperparameters: {'classifier': 'RandomForest', 'n_estimators': 1060, 'max_depth': 92.17985059870648}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=33, value=0.760569105691057, datetime_start=datetime.datetime(2020, 7, 28, 15, 20, 17, 356027), datetime_complete=datetime.datetime(2020, 7, 28, 15, 20, 19, 901204), params={'classifier': 'RandomForest', 'n_estimators': 1060, 'max_depth': 92.17985059870648}, distributions={'classifier': CategoricalDistribution(choices=('RandomForest', 'SVC')), 'n_estimators': IntUniformDistribution(high=2000, low=200, step=10), 'max_depth': LogUniformDistribution(high=100, low=10)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=33, state=TrialState.COMPLETE)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'RandomForest',\n",
       " 'n_estimators': 1060,\n",
       " 'max_depth': 92.17985059870648}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30, n_estimators=330)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf=RandomForestClassifier(n_estimators=330,max_depth=30)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93 14]\n",
      " [16 31]]\n",
      "0.8051948051948052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       107\n",
      "           1       0.69      0.66      0.67        47\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.77      0.76      0.77       154\n",
      "weighted avg       0.80      0.81      0.80       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred=rf.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
